#ifndef __COMP_IO_SCHEDULER_H__
#define __COMP_IO_SCHEDULER_H__

/**
 * Copyright 2014 Open Connectome Project (http://openconnecto.me)
 * Written by Da Zheng (zhengda1936@gmail.com)
 *
 * This file is part of SAFSlib.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 * This is a I/O scheduler for requests generated by user tasks.
 * It is only used in global_cached_io.
 */
class comp_io_scheduler
{
	// If user computation has generated too many requests, we may not
	// complete a user computation (we can't fetch all requests generated
	// by it). We have to keep the incomplete computation here, and we
	// will try to fetch more requests from it later.
	fifo_queue<user_compute *> incomplete_computes;
	// The I/O instance where the I/O scheduler works on.
	io_interface *io;

public:
	class compute_iterator {
		fifo_queue<user_compute *>::const_iterator it;
	public:
		compute_iterator(const fifo_queue<user_compute *> &computes,
				bool end): it(&computes) {
			if (end)
				it = computes.get_end();
		}

		user_compute *operator*() const {
			return *it;
		}

		compute_iterator &operator++() {
			++it;
			return *this;
		}

		bool operator==(const compute_iterator &it) const {
			return this->it == it.it;
		}

		bool operator!=(const compute_iterator &it) const {
			return this->it != it.it;
		}
	};

	/**
	 * TODO
	 * The iterator should only iterate on the user tasks with requests.
	 */

	compute_iterator get_begin() const {
		return compute_iterator(incomplete_computes, false);
	}

	compute_iterator get_end() const {
		return compute_iterator(incomplete_computes, true);
	}

	comp_io_scheduler(int node_id);

	virtual ~comp_io_scheduler() {
		assert(incomplete_computes.is_empty());
	}

	virtual size_t get_requests(fifo_queue<io_request> &reqs) = 0;

	void set_io(io_interface *io) {
		this->io = io;
	}

	io_interface *get_io() const {
		return io;
	}

	void add_compute(user_compute *compute) {
		// We have to make sure the computation has requested new data
		// successfully, otherwise, it may not be executed again.
		if (!compute->test_flag(user_compute::IN_QUEUE)) {
			compute->inc_ref();
			incomplete_computes.push_back(compute);
			compute->set_flag(user_compute::IN_QUEUE, true);
		}
	}

	void delete_compute(user_compute *compute) {
		assert(compute->test_flag(user_compute::IN_QUEUE));
		compute->set_flag(user_compute::IN_QUEUE, false);
		compute->dec_ref();
		assert(compute->get_ref() == 0);
		compute_allocator *alloc = compute->get_allocator();
		alloc->free(compute);
	}

	size_t get_num_incomplete_computes() {
		return incomplete_computes.get_num_entries();
	}

	bool is_empty() {
		return incomplete_computes.is_empty();
	}

	/**
	 * Garbage collect user compute tasks.
	 */
	void gc_computes();
};

#endif
